# 회의록

주제 변경 사항: 시간 별 버스정류장 혼잡도 분석 예측 -> 인스타그램, 네이버 View 등의 데이터 크롤링으로 여행지 추천
- 변경 사유: 선택한 버스 관련 데이터가 크롤링하기에 적합하지 않아, 비교적 쉽게 접근할 수 있는 SNS를 통해 데이터 크롤링 후 여행지를 추천하고자 함

프로젝트 순서: 크롤링 > 데이터 추출 > 전처리 작업 > 맵리듀스 > 분석

# Project 일지
**2023-12-01** 좌민서 & 최건호: 네이버에서 웹 크롤링으로 제목을 가져올 수 있는 갯수가 view(블로그)에서 페이지가 사라져 최대 60개 밖에 나오지 않음 
                          -> 네이버 api를 통해 상당항 양의 제목을 추출할 수 있음 (https://developers.naver.com/docs/serviceapi/search/blog/blog.md#%EB%B8%94%EB%A1%9C%EA%B7%B8)

**2023-12-02** 
  - 네이버 api를 통해 블로그(view) 제목 크롤링 결정
  - 검색 단어 결정
  - 데이터 추출
  - 전처리 작업 공유

  김경민 & 함범준: 인스타그램 해시태그 검색 크롤링 시 인기 게시물 30개만 나타나 많은 양의 데이터를 가져올 수 없는 문제 발생                  
&nbsp;&nbsp;&nbsp;&nbsp;  -> 수작업으로 도시별(약 17개)로 나눠서 여행관련 태그로 17*30 * N개라도 가져올 수 있음

**2023-12-03** 김경민 & 함범준: 인스타그램 크롤링 데이터에서 해시태그(#)와 단어 분리하여 재업로드 ex) #서울여행 -> 서울여행

**2023-12-04** \
김경민 & 함범준: 인스타그램 크롤링 데이터 csv 열이 (content, extracted_tags, place)로 구성되어 있었는데, 네이버 크롤링 데이터와 통일성을 갖게 하고 전처리 편의성을 위해 content열에 모든 정보를 포함하기로 함(본문에 해시태그도 있으므로 content + place)

좌민서 & 최건호: 네이버 api를 통해 얻은 데이터 형태소 분석 및 품사 태깅을 통해 고유 명사(장소) 추출
  - kkma: 9분 40초 -> 성능이 기묘함 ex) '몽돌해변' -> '몽','돌','해변' 와 같이 필요이상으로 명사를 분리해서 나중에 카운트하는데 의미가 없을거같음
  - okt: 30초 -> 성능도 좋고 속도도 빠름 
  - komoran
  - Mecab: 맥 OS에서만 지원된다고 되어있어 4명중 3명이 window를 쓰기에 적합하지 않다고 판단

reference: https://konlpy.org/ko/v0.4.3/morph/#comparison-between-pos-tagging-classes


**2023-12-05**
명사만을 추출한 결과에서 여행, 여행지, 명소, 과같은 실질적인 장소가 아닌 명사들까지 추출되기 때문에 실제 여행지와 관련없는 명사들을 빼야함(ex. 여행, 명소, 추천, 여행, 주말, 테마등등 실질적 장소가 아닌 명사) + 각 지역의 명사도 빼야함 (ex. 제주도 csv의 경우에 제주, 제주도 제주특별자치도)
->이를 txt에 공용으로 빼야할것과 지역별로 빼야할것을 txt로 저장 

- 최건호: 크롤링한 데이터에서 상당히 많은 수가 중복된 데이터로 발견(같은 게시물 제목이 100개씩 중복) 크롤링코드를 다시 확인해보고 그래도 데이터양이 부족하면 크롤링 범위를 늘려야함
          -> 수정하니 데이터양이 총18700개가 나온다(크롤링 제목을 옮기는 과정에서 for문을 2중으로 사용해서 뻥튀기가 되어버렸었다.

**2023-12-06**
네이버 크롤링 코드 오류를 수정해 데이터 양이 총 18700개로 대폭 감소 -> 기존 17개의 도시에서 세분화하여 크롤링하기로 결정 (ex 강원_강릉시)
도시를 세분화하여 크롤링했을 때 얻을 수 있는 데이터는 230,000개 -> 세분화한 데이터를 다시 기존 17개 도시로 묶기 
https://github.com/BDP-Term-Project/Term-Project/tree/main/data_collect/detail_place_sigun/combine_sido


**2023-12-07**
  mapreduce 과정에서 한글이 utf-8 바이트로 깨지는 현상 발생(split하고 map & reduce하는 과정에서 바이트로 인식해서 결과가 깨지는 것으로 판단)

okt 형태소 분석기로 사용해서 결과를 봤지만 명소 이름이 너무 잘게 명사로 쪼개져서(ex. 용오름 -> 용, 오름 으로 분리해서 인식) 쓰기에는 힘들 것 같다는 판단이 섰고, nltk를 단어 토큰화를 통해 공동 제외 명사에서 겹치는 것을 빼는 게 좋을 것 같다는 의견 반영

김경민 & 함범준: 인스타 크롤링 데이터에서 네이버 데이터와 형식 통일하기 위해 첫 번째 행(content) 제거

좌민서: mapreduce 결과에서 명소 이름 출력 성능이 우리가 기대한 것에 미치지 못함 -> 공동 제외 명사 목록을 다시 구성해야 될 필요가 있음
 -> 기존 kkma, okt, komoran, nltk에서 twitter까지 추가해서 맵리듀스 결과 확인 -> 결론:형태소 분석 라이브러리를 twitter로 재선택
 -> twitter가 한국에서 만든 형태소 분석 라이브러리라 제일 납득할만한 결과를 낼 수 있는 것 같음

mapreduce 결과 인코딩 문제 해결.

